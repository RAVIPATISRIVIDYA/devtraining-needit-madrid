{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Poisonattack2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBwqTOvcxTYR9wFkT5gM2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAVIPATISRIVIDYA/devtraining-needit-madrid/blob/master/Poisonattack2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADht2pzy1YFM",
        "outputId": "06f56e56-cf05-4ee3-bc79-0c6dad73ac1b"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.8.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Collecting numba>=0.53.1\n",
            "  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.22.2.post1)\n",
            "Collecting llvmlite<0.38,>=0.37.0rc1\n",
            "  Downloading llvmlite-0.37.0-cp37-cp37m-manylinux2014_x86_64.whl (26.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3 MB 83 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.8.1 llvmlite-0.37.0 numba-0.54.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofL0ECMu1oiu"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from art.utils import load_dataset\n",
        "from art.utils import load_dataset\n",
        "from art.attacks.poisoning.perturbations.image_perturbations import add_pattern_bd, add_single_bd\n",
        "from art.utils import load_mnist, preprocess,load_cifar10\n",
        "from art.estimators.classification import KerasClassifier\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import art\n",
        "import pprint\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k31gt7T-1qvA"
      },
      "source": [
        "def generate_backdoor(\n",
        "    x_clean, y_clean, num_poison, backdoor_type=\"pattern\", sources=np.arange(10), targets=(np.arange(10) + 1) % 10\n",
        "):\n",
        "\n",
        "    max_val = np.max(x_clean)\n",
        "\n",
        "    x_poison = np.copy(x_clean)\n",
        "    y_poison = np.copy(y_clean)\n",
        "    is_poison = np.zeros(np.shape(y_poison))\n",
        "\n",
        "    for i, (src, tgt) in enumerate(zip(sources, targets)):\n",
        "      n_points_in_tgt = np.size(np.where(y_clean == tgt))\n",
        "      num_poison = num_poison #round((percent_poison * n_points_in_tgt) / (1 - percent_poison))\n",
        "      print(num_poison)\n",
        "      \n",
        "      src_imgs = x_clean[np.ravel(y_clean == src)]\n",
        "      # src_imgs = x_clean[y_clean == src]\n",
        "\n",
        "      n_points_in_src = np.shape(src_imgs)[0]\n",
        "      indices_to_be_poisoned = np.random.choice(n_points_in_src, num_poison)\n",
        "\n",
        "      imgs_to_be_poisoned = np.copy(src_imgs[indices_to_be_poisoned])\n",
        "      if backdoor_type == \"pattern\":\n",
        "          imgs_to_be_poisoned = add_pattern_bd(x=imgs_to_be_poisoned, pixel_value=max_val)\n",
        "      elif backdoor_type == \"pixel\":\n",
        "          imgs_to_be_poisoned = add_single_bd(imgs_to_be_poisoned, pixel_value=max_val)\n",
        "      x_poison = np.append(x_poison, imgs_to_be_poisoned, axis=0)\n",
        "      # import pdb\n",
        "      # pdb.set_trace()\n",
        "      y_poison = np.append(y_poison, np.ones((num_poison,1)) * tgt, axis=0)\n",
        "      # y_poison = np.append(y_poison, np.ones(num_poison) * tgt, axis=0)\n",
        "      is_poison = np.append(is_poison, np.ones(num_poison))\n",
        "\n",
        "    is_poison = is_poison != 0\n",
        "\n",
        "    return is_poison, x_poison, y_poison\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdJRhTqZ1tLh"
      },
      "source": [
        "max_val = np.max(x_clean)\n",
        "\n",
        "    x_poison = np.copy(x_clean)\n",
        "    y_poison = np.copy(y_clean)\n",
        "    is_poison = np.zeros(np.shape(y_poison))\n",
        "\n",
        "    for i, (src, tgt) in enumerate(zip(sources, targets)):\n",
        "      n_points_in_tgt = np.size(np.where(y_clean == tgt))\n",
        "      num_poison = num_poison #round((percent_poison * n_points_in_tgt) / (1 - percent_poison))\n",
        "      print(num_poison)\n",
        "      \n",
        "      src_imgs = x_clean[np.ravel(y_clean == src)]\n",
        "      # src_imgs = x_clean[y_clean == src]\n",
        "\n",
        "      n_points_in_src = np.shape(src_imgs)[0]\n",
        "      indices_to_be_poisoned = np.random.choice(n_points_in_src, num_poison)\n",
        "\n",
        "      imgs_to_be_poisoned = np.copy(src_imgs[indices_to_be_poisoned])\n",
        "      if backdoor_type == \"pattern\":\n",
        "          imgs_to_be_poisoned = add_pattern_bd(x=imgs_to_be_poisoned, pixel_value=max_val)\n",
        "      elif backdoor_type == \"pixel\":\n",
        "          imgs_to_be_poisoned = add_single_bd(imgs_to_be_poisoned, pixel_value=max_val)\n",
        "      x_poison = np.append(x_poison, imgs_to_be_poisoned, axis=0)\n",
        "      # import pdb\n",
        "      # pdb.set_trace()\n",
        "      y_poison = np.append(y_poison, np.ones((num_poison,1)) * tgt, axis=0)\n",
        "      # y_poison = np.append(y_poison, np.ones(num_poison) * tgt, axis=0)\n",
        "      is_poison = np.append(is_poison, np.ones(num_poison))\n",
        "\n",
        "    is_poison = is_poison != 0\n",
        "\n",
        "    return is_poison, x_poison, y_poison"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUCzfv3W1zmC",
        "outputId": "17c6f8f3-176d-4e65-bf35-5f87d800338f"
      },
      "source": [
        "(x_raw, y_raw), (x_raw_test, y_raw_test), min_, max_ = load_cifar10(raw=True)\n",
        "n_train = np.shape(x_raw)[0]\n",
        "num_selection = 50000\n",
        "random_selection_indices = np.random.choice(n_train, num_selection)\n",
        "x_raw = x_raw[random_selection_indices]\n",
        "y_raw = y_raw[random_selection_indices]\n",
        "print(x_raw.shape,y_raw.shape)\n",
        "# num_images_to_poison= 2000\n",
        "perc_poison= 0.01#num_images_to_poison/x_raw.shape[0]\n",
        "(is_poison_train, x_poisoned_raw, y_poisoned_raw) = generate_backdoor(x_raw, y_raw, num_poison=1500)\n",
        "# x_train, y_train = preprocess(x_poisoned_raw, y_poisoned_raw)\n",
        "x_train,y_train = x_poisoned_raw/255,to_categorical(y_poisoned_raw,10)\n",
        "# Add channel axis:\n",
        "# x_train = np.expand_dims(x_train, axis=3)\n",
        "# Poison test data\n",
        "(is_poison_test, x_poisoned_raw_test, y_poisoned_raw_test) = generate_backdoor(x_raw_test, y_raw_test, num_poison=100)\n",
        "# x_test, y_test = preprocess(x_poisoned_raw_test, y_poisoned_raw_test)\n",
        "x_test,y_test = x_poisoned_raw_test/255,to_categorical(y_poisoned_raw_test,10)\n",
        "# Add channel axis:\n",
        "# x_test = np.expand_dims(x_test, axis=3)\n",
        "# Shuffle training data so poison is not together\n",
        "n_train = np.shape(y_train)[0]\n",
        "shuffled_indices = np.arange(n_train)\n",
        "np.random.shuffle(shuffled_indices)\n",
        "x_train = x_train[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]\n",
        "is_poison_train = is_poison_train[shuffled_indices]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "1500\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyF3W_PVCLZu",
        "outputId": "e581ebdd-1823-4255-d447-991c87f722a6"
      },
      "source": [
        "x_raw.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S37IHin13nt",
        "outputId": "1cb2fc33-2d8d-4c6c-ba91-0604ae63f032"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=x_train.shape[1:]))\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
        "\n",
        "classifier.fit(x_train, y_train, nb_epochs=30, batch_size=128)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 65000 samples\n",
            "Epoch 1/30\n",
            "65000/65000 [==============================] - 11s 170us/sample - loss: 1.7862 - accuracy: 0.3379\n",
            "Epoch 2/30\n",
            "65000/65000 [==============================] - 11s 166us/sample - loss: 1.3961 - accuracy: 0.4895\n",
            "Epoch 3/30\n",
            "65000/65000 [==============================] - 11s 167us/sample - loss: 1.2277 - accuracy: 0.5634\n",
            "Epoch 4/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 1.1144 - accuracy: 0.6014\n",
            "Epoch 5/30\n",
            "65000/65000 [==============================] - 11s 166us/sample - loss: 1.0306 - accuracy: 0.6328\n",
            "Epoch 6/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.9556 - accuracy: 0.6602\n",
            "Epoch 7/30\n",
            "65000/65000 [==============================] - 11s 164us/sample - loss: 0.8954 - accuracy: 0.6789\n",
            "Epoch 8/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.8405 - accuracy: 0.6988\n",
            "Epoch 9/30\n",
            "65000/65000 [==============================] - 11s 164us/sample - loss: 0.8021 - accuracy: 0.7129\n",
            "Epoch 10/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.7558 - accuracy: 0.7282\n",
            "Epoch 11/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.7265 - accuracy: 0.7365\n",
            "Epoch 12/30\n",
            "65000/65000 [==============================] - 11s 166us/sample - loss: 0.6836 - accuracy: 0.7524\n",
            "Epoch 13/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.6497 - accuracy: 0.7657\n",
            "Epoch 14/30\n",
            "65000/65000 [==============================] - 11s 166us/sample - loss: 0.6261 - accuracy: 0.7730\n",
            "Epoch 15/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.6093 - accuracy: 0.7787\n",
            "Epoch 16/30\n",
            "65000/65000 [==============================] - 11s 166us/sample - loss: 0.5774 - accuracy: 0.7904\n",
            "Epoch 17/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.5606 - accuracy: 0.7964\n",
            "Epoch 18/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.5449 - accuracy: 0.8021\n",
            "Epoch 19/30\n",
            "65000/65000 [==============================] - 11s 166us/sample - loss: 0.5384 - accuracy: 0.8020\n",
            "Epoch 20/30\n",
            "65000/65000 [==============================] - 11s 164us/sample - loss: 0.5156 - accuracy: 0.8104\n",
            "Epoch 21/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.5048 - accuracy: 0.8143\n",
            "Epoch 22/30\n",
            "65000/65000 [==============================] - 11s 166us/sample - loss: 0.4903 - accuracy: 0.8212\n",
            "Epoch 23/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.4848 - accuracy: 0.8218\n",
            "Epoch 24/30\n",
            "65000/65000 [==============================] - 11s 165us/sample - loss: 0.4713 - accuracy: 0.8255\n",
            "Epoch 25/30\n",
            "65000/65000 [==============================] - 11s 173us/sample - loss: 0.4538 - accuracy: 0.8330\n",
            "Epoch 26/30\n",
            "65000/65000 [==============================] - 11s 177us/sample - loss: 0.4533 - accuracy: 0.8323\n",
            "Epoch 27/30\n",
            "65000/65000 [==============================] - 11s 176us/sample - loss: 0.4390 - accuracy: 0.8381\n",
            "Epoch 28/30\n",
            "65000/65000 [==============================] - 11s 173us/sample - loss: 0.4352 - accuracy: 0.8406\n",
            "Epoch 29/30\n",
            "65000/65000 [==============================] - 11s 171us/sample - loss: 0.4325 - accuracy: 0.8398\n",
            "Epoch 30/30\n",
            "65000/65000 [==============================] - 11s 172us/sample - loss: 0.4193 - accuracy: 0.8442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaQf03G716pz",
        "outputId": "1d738f4d-98ec-41b9-85d3-24d59f1d7a35"
      },
      "source": [
        "preds = np.argmax(classifier.predict(x_test), axis=1)\n",
        "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "print(\"\\nTest accuracy: %.2f%%\" % (acc * 100))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy: 67.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO_Pz-cA19Sz",
        "outputId": "1df81e19-0c86-467d-d937-c0454c758692"
      },
      "source": [
        "preds = np.argmax(classifier.predict(x_test[is_poison_test]), axis=1)\n",
        "acc = np.sum(preds == np.argmax(y_test[is_poison_test], axis=1)) / y_test[is_poison_test].shape[0]\n",
        "print(\"\\nPoisonous test set accuracy (i.e. effectiveness of poison): %.2f%%\" % (acc * 100))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Poisonous test set accuracy (i.e. effectiveness of poison): 61.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvlknH8z1_sT",
        "outputId": "0fd9eb49-fe4c-43f3-9fd6-8f08599fda27"
      },
      "source": [
        "preds = np.argmax(classifier.predict(x_test[is_poison_test == 0]), axis=1)\n",
        "acc = np.sum(preds == np.argmax(y_test[is_poison_test == 0], axis=1)) / y_test[is_poison_test == 0].shape[0]\n",
        "print(\"\\nClean test set accuracy: %.2f%%\" % (acc * 100))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Clean test set accuracy: 68.54%\n"
          ]
        }
      ]
    }
  ]
}